"""–¢–µ—Å—Ç—ã –¥–ª—è LLM –∫–ª–∏–µ–Ω—Ç–∞ - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è."""

import asyncio
import sys
import os
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –≤ path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –ò–ú–ü–û–†–¢–´
from characters.alice import AliceCharacter
from services.llm.ollama_client import OllamaClient
from models.base import User, BaseMessage, MessageRole, MessageType


def create_test_user() -> User:
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    return User(
        id=12345,
        username="tester",
        first_name="–¢–µ—Å—Ç–µ—Ä",
        last_name="–¢–µ—Å—Ç–æ–≤–∏—á",
        language_code="ru",
        created_at=datetime.now(),
        last_seen=datetime.now(),
        is_premium=False
    )


def test_ollama_connection():
    """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama."""
    print("=== –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama ===")
    
    try:
        import ollama
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
        models_response = ollama.list()
        print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Ollama —É—Å–ø–µ—à–Ω–æ!")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞
        if hasattr(models_response, 'models'):
            models_list = models_response.models
        elif isinstance(models_response, dict) and 'models' in models_response:
            models_list = models_response['models']
        else:
            print(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: {type(models_response)}")
            return False
        
        print(f"–ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(models_list)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –º–æ–¥–µ–ª–∏
        for i, model in enumerate(models_list[:3]):
            if hasattr(model, 'model'):
                name = model.model
            elif isinstance(model, dict) and 'model' in model:
                name = model['model']
            elif hasattr(model, 'name'):
                name = model.name
            else:
                name = str(model)
            print(f"  {i+1}. {name}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        print("\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print("1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama: curl -fsSL https://ollama.com/install.sh | sh")
        print("2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä: ollama serve")
        print("3. –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å: ollama pull llama3.2:3b")
        return False


async def test_llm_client():
    """–¢–µ—Å—Ç LLM –∫–ª–∏–µ–Ω—Ç–∞."""
    print("\n=== –¢–µ—Å—Ç LLM –∫–ª–∏–µ–Ω—Ç–∞ ===")
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        character = AliceCharacter()
        llm = OllamaClient(
            model_name="auto",
            temperature=0.7,
            max_tokens=200
        )
        
        print(f"‚úÖ LLM –∫–ª–∏–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω")
        print(f"–ú–æ–¥–µ–ª—å: {llm.model_name}")
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å
        print("üîÑ –ü–æ–ø—ã—Ç–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏...")
        initialized = await llm.initialize()
        
        if not initialized:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å LLM –∫–ª–∏–µ–Ω—Ç")
            return False
        
        print(f"‚úÖ LLM –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–æ–¥–µ–ª—å—é: {llm.model_name}")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        test_user = create_test_user()
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        test_messages_text = [
            "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
            "–†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ –∫—Ä–∞—Ç–∫–æ",
            "–°–ø–∞—Å–∏–±–æ!"
        ]
        
        print("\n--- –î–∏–∞–ª–æ–≥ —Å LLM ---")
        for i, message_text in enumerate(test_messages_text, 1):
            print(f"\n{i}. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {message_text}")
            
            try:
                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
                test_message = BaseMessage(
                    id=f"test_{i}",
                    content=message_text,
                    role=MessageRole.USER,
                    message_type=MessageType.TEXT,
                    timestamp=datetime.now(),
                    metadata={"user_id": test_user.id}
                )
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
                response = await llm.generate_response(
                    messages=[test_message],
                    user=test_user
                )
                
                print(f"   –ê–ª–∏—Å–∞: {response}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º
                if any(char in response.lower() for char in '–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è'):
                    print("   ‚úÖ –û—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ")
                else:
                    print("   ‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–æ –Ω–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ")
                    
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
        
        # –¢–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è
        print(f"\n--- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è ---")
        health = await llm.check_health()
        print(f"–°–æ—Å—Ç–æ—è–Ω–∏–µ LLM: {'‚úÖ –ó–¥–æ—Ä–æ–≤' if health else '‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–µ–Ω'}")
        
        # –¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        available_models = llm.get_available_models()
        print(f"–î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(available_models)}")
        for model in available_models[:3]:
            print(f"  - {model}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è LLM: {e}")
        import traceback
        traceback.print_exc()
        return False


async def run_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤."""
    print("üß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ LLM\n")
    
    # –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    if not test_ollama_connection():
        print("\n‚ùå –¢–µ—Å—Ç—ã –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º")
        return
    
    # –¢–µ—Å—Ç –∫–ª–∏–µ–Ω—Ç–∞
    success = await test_llm_client()
    
    if success:
        print("\n‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã LLM –ø—Ä–æ–π–¥–µ–Ω—ã!")
    else:
        print("\n‚ùå –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏")


if __name__ == "__main__":
    asyncio.run(run_tests())